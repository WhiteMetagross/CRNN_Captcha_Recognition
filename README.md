# CAPTCHA Recognition with CRNN and CBA Mechanism.

This project provides a complete, end to end pipeline for training and deploying a Deep Learning model to solve complex CAPTCHA images. The solution uses a hybrid CRNN architecture with attention mechanisms, achieves high accuracy, and demonstrates a full lifecycle from data preparation to deployment in a C++ environment via ONNX.

-----

## Features

  * **A Good Architecture**: It implements a hybrid model combining a ResNet style CNN backbone, Convolutional Block Attention Module (CBAM), a bidirectional LSTM, and a Transformer Encoder for robust feature extraction and sequence modeling.
  * **High Accuracy**: It achieves excellent performance on the test set with **95.08% Character Accuracy** and **86.37% Sequence Accuracy**.
  * **End to End Workflow**: It includes scripts for every step: dataset preparation, model training with mixed-precision support, visualization of training metrics, model evaluation, and inference in both Python and C++.
  * **Advanced Data Augmentation**: It leverages the `albumentations` library to create a robust training dataset by applying various transformations like noise, blur, and color jitters.
  * **Deployment Ready**: The trained PyTorch model can be easily exported to the ONNX format for high-performance, cross-platform inference in environments like C++. The inference speed on a test set image is about **150 milliseconds** on python, and **115 milliseconds** on C++ based inference programs.

-----

## Model Architecture

The model is a custom built Convolutional Recurrent Neural Network (CRNN) that integrates multiple advanced concepts to maximize accuracy. The architecture is defined in `model.py` and its hyperparameters are managed in `config.json`.

The model's architecture is a complex variant of the CRNN design, which is highly effective for sequence recognition tasks in images. It's structured in two primary stages:

  * **Convolutional Backbone**: The first stage is a deep convolutional neural network (`FeatureExtractor`) that functions as a visual feature extractor. It processes the input CAPTCHA image through a series of residual blocks (`ResBlock`) that are enhanced with a Convolutional Block Attention Module (CBAM). This allows the model to learn a sequence of relevant visual features from left to right across the image.
  * **Sequence Modeling**: The sequence of features from the CNN is then passed to the second stage for contextual modeling. This stage uses a hybrid approach, where a bidirectional LSTM processes the feature sequence, and its output is further refined by a `TransformerEncoder` layer. This uses self attention to model complex, long-range dependencies between different parts of the CAPTCHA.

The model is trained with a Connectionist Temporal Classification (CTC) loss function. This is critical for sequence tasks as it eliminates the need for precise alignment between the input features and the output characters, allowing the model to learn from unsegmented data.

-----

## Dataset and Performance

### Dataset

The model was trained on the **Huge CAPTCHA Dataset** that's been made by the author, **Mridankan Mandal**, which has been made available on Kaggle. This dataset contains a large number of CAPTCHA images with alphanumeric characters, where the label for each image is its filename.

  * **Link**: [Huge CAPTCHA Dataset on Kaggle](https://www.kaggle.com/datasets/redzapdos123/huge-captcha-dataset)

### Performance Metrics

The model achieves high accuracy on both the validation and unseen test sets.

| Metric             | Validation Set | Test Set |
| ------------------ | :------------: | :------: |
| Sequence Accuracy  |     86.4%      | 86.37%   |
| Character Accuracy |     95.1%      | 95.08%   |

### Training Performance

The training process is optimized for modern hardware. An approximate training time of **11 minutes per epoch** is achieved on an RTX 4060 GPU with 8GB of VRAM. The `train.py` script contributes to this performance by implementing mixed-precision training, which uses both 16-bit and 32-bit floating-point types to decrease memory usage and accelerate computations on compatible GPUs.

### Training Metrics Plot

The following plot, generated by `model_metrics_plotter.py`, shows the model's key metrics over the course of the training process.

-----

## Setup and Usage

This section provides a complete guide to setting up the environment and running the project.

### 1\. Prerequisites

  * Python 3.8+
  * Git
  * **For C++ Inference**:
      * A modern C++ compiler (e.g., GCC, Clang, MSVC)
      * CMake (version 3.16 or higher)
      * OpenCV library
      * ONNX Runtime library

### 2\. Installation

First, clone the repository and navigate into the project directory.

```bash
git clone https://github.com/WhiteMetagross/ProjectAA
cd ProjectAA
```

Next, create a Python virtual environment and install the required dependencies from the `requirements.txt` file.

```bash

python -m venv venv
source venv/bin/activate

pip install -r requirements.txt
```

### 3\. Step-by-Step Workflow

#### Step 1: Prepare the Dataset

Download the dataset and place all images in a single directory. Run the `dataset_preparer.py` script to automatically split the data and generate analysis reports. Note that you may need to update the `input_dir` and `output_dir` paths in the script to match your local setup.

```bash
python dataset_preparer.py
```

#### Step 2: Configure the Project

All project settings are managed in `config.json`. Before training, review this file to ensure the data paths (`train_path`, `val_path`) and training parameters are set as desired.

#### Step 3: Train the Model

Start the training process by running `train.py`.

  * **Start a new training session:**

    ```bash
    python train.py --config config.json
    ```

  * **Resume training from a checkpoint:**

    ```bash
    python train.py --config config.json --resume ./checkpoints/checkpoint_epoch_X.pt
    ```

#### Step 4: Visualize Training Progress

Use the `model_metrics_plotter.py` script to parse the `training.log` file and generate plots for loss, accuracy, and other metrics.

```bash
python model_metrics_plotter.py --log_path ./logs/training.log --output_dir ./visualizations
```

#### Step 5: Evaluate the Model

Evaluate the final model's performance on the test set using `evaluate.py`.

```bash
python evaluate.py --config config.json --input_path ./dataset/test/
```

#### Step 6: Run Inference

##### A. Python Inference

To quickly test the model on images, use `inference.py`.

  * **On a single image:**

    ```bash
    python inference.py --input_path /path/to/your/captcha.png
    ```

  * **On a folder of images:**

    ```bash
    python inference.py --input_path /path/to/your/folder/
    ```

##### B. C++ Deployment

For high-performance environments, deploy the model in C++.

1.  **Export to ONNX**: Convert the trained PyTorch model to the ONNX format.

    ```bash
    python export_onnx.py --output captcha_solver.onnx
    ```

2.  **Build the C++ Project**: Use CMake to build the C++ inference executable.

    ```bash
    mkdir build && cd build
    cmake ..
    cmake --build .
    ```

3.  **Run C++ Inference**: From the `build` directory, execute the compiled program.

    ```bash
    ./inference ../captcha_solver.onnx /path/to/your/captcha.png
    ```

-----

## File Structure

```
.
├── checkpoints/         #Saved model checkpoints
├── dataset/             #Processed dataset (train/val/test splits)
├── logs/                #Training logs (training.log)
├── models/              #Best trained model (best_model.pt)
├── visualizations/      #Output plots from analysis scripts
├── CMakeLists.txt       #Build script for C++ inference
├── config.json          #All project configurations and hyperparameters
├── data.py              #PyTorch Dataset and DataLoader classes
├── dataset_preparer.py  #Script to split and analyze the raw dataset
├── evaluate.py          #Script to evaluate model performance on the test set
├── export_onnx.py       #Script to convert PyTorch model to ONNX
├── inference.cpp        #C++ inference source code using ONNX Runtime
├── inference.py         #Python inference script
├── model.py             #The CRNN model architecture definition
├── model_metrics_plotter.py #Script to visualize metrics from training logs
├── requirements.txt     #Python dependencies
├── train.py             #Main training script
└── utils.py             #Utility functions (metrics, decoders, logging)

```


